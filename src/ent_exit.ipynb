{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/input/train.csv')\n",
    "enbase = pd.read_csv('../data/input/1entbase.csv')\n",
    "alter = pd.read_csv('../data/input/2alter.csv')\n",
    "branch = pd.read_csv('../data/input/3branch.csv')\n",
    "invest = pd.read_csv('../data/input/4invest.csv')\n",
    "right = pd.read_csv('../data/input/5right.csv')\n",
    "project = pd.read_csv('../data/input/6project.csv')\n",
    "lawsuit = pd.read_csv('../data/input/7lawsuit.csv')\n",
    "breakfaith = pd.read_csv('../data/input/8breakfaith.csv')\n",
    "recruit = pd.read_csv('../data/input/9recruit.csv')\n",
    "qualification = pd.read_csv('../data/input/10qualification.csv')\n",
    "test = pd.read_csv('../data/input/evaluation_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enbase = enbase.fillna(value={'MPNUM': 0, 'INUM': 0, 'ENUM': 0, 'FINZB': 0, 'FSTINUM': 0, 'TZINUM': 0})  # 未处理 HY 和 ZCZB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enbase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = enbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = pd.merge(train, dataset, on='EID', how='left')\n",
    "testset = pd.merge(test, dataset, on='EID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EID 前面的字母代表不同省份，已提供了 PROV 列，因此字母是冗余信息，直接舍弃\n",
    "trainset['EID'] = trainset['EID'].str.extract('(\\d+)').astype(int)\n",
    "testset['EID'] = testset['EID'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = trainset.drop(['TARGET', 'ENDDATE'], axis=1)\n",
    "train_label = trainset.TARGET.values\n",
    "test_feature = testset\n",
    "test_index = testset.EID.values\n",
    "print train_feature.shape, train_label.shape, test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'rounds': 10000,\n",
    "    'folds': 3\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "#     'objective': 'rank:pairwise',\n",
    "    'stratified': True,\n",
    "    'scale_pos_weights ': 0,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 1,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'lambda': 1,\n",
    "\n",
    "    'eta': 0.02,\n",
    "    'seed': 20,\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_cv(train_feature, train_label, params, rounds):\n",
    "    params['scale_pos_weights '] = float(len(train_label[train_label == 0])) / len(train_label[train_label == 1])\n",
    "    dtrain = xgb.DMatrix(train_feature, label=train_label)\n",
    "    num_round = rounds\n",
    "    print 'run cv: ' + 'round: ' + str(rounds)\n",
    "    res = xgb.cv(params, dtrain, num_round, verbose_eval=10, early_stopping_rounds=100)\n",
    "    return len(res)\n",
    "\n",
    "\n",
    "def xgb_predict(train_feature, train_label, test_feature, rounds, params):\n",
    "    params['scale_pos_weights '] = float(len(train_label[train_label == 0])) / len(train_label[train_label == 1])\n",
    "    dtrain = xgb.DMatrix(train_feature, label=train_label)\n",
    "    dtest = xgb.DMatrix(test_feature, label=np.zeros(test_feature.shape[0]))\n",
    "    watchlist = [(dtrain, 'train')]\n",
    "    num_round = rounds\n",
    "    model = xgb.train(params, dtrain, num_round, watchlist, verbose_eval=50)\n",
    "    predict = model.predict(dtest)\n",
    "    return model, predict\n",
    "\n",
    "\n",
    "def store_result(test_index, pred, threshold, name):\n",
    "    result = pd.DataFrame({'EID': test_index, 'FORTARGET': 0, 'PROB': pred})\n",
    "    mask = result['PROB'] >= threshold\n",
    "    result.at[mask, 'FORTARGET'] = 1\n",
    "    # result['PROB'] = result['PROB'].apply(lambda x: round(x, 4))\n",
    "    result.to_csv('../data/output/sub/' + name + '.csv', index=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = xgb_cv(train_feature, train_label, params, config['rounds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(600,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, pred = xgb_predict(train_feature, train_label, test_feature, iterations, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(model.get_fscore().items(), columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "importance.to_csv('../data/output/feat_imp/importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = store_result(test_index, pred, 0.5, '1122-xgb-entbase_only.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
